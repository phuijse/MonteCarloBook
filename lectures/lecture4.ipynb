{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ley de los grandes números para variables no iid\n",
    "\n",
    "Previamente vimos que el promedio de un conjunto de $N$ variables independientes e idénticamente distribuidas (iid) converge a su valor esperado cuando $N$ es grande\n",
    "\n",
    "$$\n",
    "\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{i=1}^N X_i = \\mu\n",
    "$$\n",
    "\n",
    "También vimos que la cadena de markov, un proceso estocástico donde no se cumple el supuesto iid, puede tener en ciertos casos una distribución estacionaria\n",
    "\n",
    "**Recordatorio:** La distribución estacionaria $\\pi$ de una cadena de Markov con matriz de transición $P$ es tal que $\\pi P = \\pi$\n",
    "\n",
    "## Teorema de ergodicidad\n",
    "\n",
    "Una cadena de Markov irreducible y aperiodica tiene una distribución estacionaria $\\pi$ única, independiente de valor del estado inicial y que cumple\n",
    "\n",
    "$$\n",
    "\\lim_{n\\to \\infty} s_j(n) = \\pi_j\n",
    "$$\n",
    "\n",
    "donde los componentes de $\\pi$ representan la fracción de tiempo que la cadena estará en cada uno de los estados luego de observarla por un largo tiempo\n",
    "\n",
    "El límite de observar la cadena por un tiempo largo es análogo al análisis de estadísticos estáticos sobre muestras grandes. Esto es el equivalente a la ley de los grandes números para el caso de la cadena de Markov\n",
    "\n",
    "\n",
    "## Nota histórica\n",
    "\n",
    "Jacob Bernoulli mostró la primera versión de la Ley de los grandes números en su Ars Conjectandi en 1713. Esta primera versión parte del supuesto de que las VAs son iid. Bernoulli era un firme creyente del destino, se oponía al libre albedrío y abogaba por el determinismo en los fenómenos aleatorios\n",
    "\n",
    "En 1913 el matemático ruso Andrei Markov celebró el bicentenario de la famosa prueba de Bernoulli organizando un simposio donde presentó su nueva versión de la Ley de los grandes números que aplica sobre la clase de procesos estocásticos que hoy llamamos procesos de Markov, de esta forma extendiendo el resultado de Bernoulli a un caso que no es iid\n",
    "\n",
    "## Más sobre la pugna de Markov y Nekrasov\n",
    "\n",
    "En aquellos tiempos Markov estaba en pugna con otro matemático ruso: Pavel Nekrasov. Nekrasov había publicado previamente que \"la independencia era una condición necesaria para la ley de los grandes números\" y que la ley de los grandes números, que se observa en estadísticas sociales, asegura entonces que las personas actuan voluntariamente y con libre albedrío. Markov reaccionó a esta afirmación desarrollando un contra-ejemplo que terminó siendo lo que hoy conocemos como los procesos de Markov \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principales usos de las cadenas de Markov\n",
    "\n",
    "Las cadenas de Markov tienen dos usos principales\n",
    "\n",
    "En primer lugar las cadenas de Markov se ocupan como **modelo o aproximación de fenómenos que evolucionan en el tiempo**. Esto es lo que vimos la lección anterior.\n",
    "\n",
    "En estos casos corresponde hacer la pregunta empírica de si acaso el fenómeno que estoy estudiando cumple con la propiedad de Markov. Por ejemplo ¿Es la evolución del clima un proceso de Markov?\n",
    "\n",
    "En segundo lugar las cadenas de Markov son un **componente fundamental de una clase de algoritmos conocidos como Markov Chain Monte Carlo** (MCMC)\n",
    "\n",
    "El objetivo de MCMC es crear sintéticamente una cadena de Markov que converge a una distribución en la cual estamos interesados y que no podemos simular de forma analítica y/o explícita\n",
    "\n",
    "MCMC es considerado una revolución en computación científica y es usado en prácticamente todos las disciplinas. \n",
    "\n",
    "\n",
    "En esta lección estudiaremos el algoritmos de Metropolis, una de las formulaciones originales de MCMC y también uno de los [diez algoritmos más importantes del Siglo XX](https://www.andrew.cmu.edu/course/15-355/misc/Top%20Ten%20Algorithms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo (MCMC)\n",
    "\n",
    "MCMC es una poderosa herramienta para muestrear y calcular valores esperados a partir de distribuciones complejas \n",
    "\n",
    "En este sentido es una extensión de la idea básica de Monte Carlo que vimos en las primeras lecciones\n",
    "\n",
    "## Monte Carlo y muestreo por importancia (IS)\n",
    "\n",
    "Sea una función $f()$ sobre una variable aleatoria con distribución $p(x)$\n",
    "\n",
    "Con Monte Carlo puedo estimar el valor esperado de esta función en base a muestras usando \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[f(X)] \\approx \\frac{1}{N} \\sum_{i=1}^N f(x_i) \\quad x_i \\sim p(x)\n",
    "$$\n",
    "\n",
    "Siempre y cuando yo pueda muestrear directamente de $p(x)$\n",
    "\n",
    "Si no puedo muestrear de $p(x)$ pero si es posible evaluarla, puedo recurrir a la técnica de muestreo por importancia (IS) que se define a cotninuación\n",
    "\n",
    "Sea una distribución de propuestas o distribución de importancia $q(x)$ de la cual yo puedo evaluar y además muestrear \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{x\\sim p(x)}[f(X)] &= \\int p(x) f(x) \\,dx = \\int q(x)  \\frac{p(x)}{q(x)} f(x) \\,dx \\nonumber \\\\\n",
    "&= \\mathbb{E}_{x\\sim q(x)}\\left[ \\frac{p(x)}{q(x)} f(X)\\right] \\nonumber \\\\\n",
    "&\\approx \\frac{1}{N} \\sum_{i=1}^N w_i f(x_i) \\quad x_i \\sim q(x) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $w_i = \\frac{p(x)}{q(x)}$ se llama la ponderación de importancia. \n",
    "\n",
    "Una distribución de importancia correcta no sólo nos permite resolver el problema sino que tiende a tener una varianza más baja que el estimador original de Monte Carlo. No es necesario escoger una distribución de importancia que sea igual a la distribución original, pero se debe tener en cuanta que que $q(x)$ debe ser tal que $p(x)=0$ cuando $q(x)=0$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Sea una linea de teléfono de soporte tecnológico que recibe en promedio 2 llamadas por minuto\n",
    "\n",
    "¿Cuál es la probabilidad de que ellos tengan que esperar por lo menos 10 minutos para recibir 9 llamadas?\n",
    "\n",
    "Usemos una simulación para resolver este problema\n",
    "\n",
    "Note como el estimador basado en IS converge más rápido y con menos varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2. # Eventos promedio por minuto\n",
    "a = 9 # Cantidad de eventos\n",
    "# La distribución gamma modela tiempos de espera para una cierta cantidad de eventos\n",
    "p = scipy.stats.gamma(a, scale=1/b) \n",
    "# La función f en esta caso me dice \n",
    "f = lambda x: x > 10\n",
    "# La función de propuesta\n",
    "q = scipy.stats.norm(scale=10)\n",
    "# Simulación\n",
    "mc_result = []\n",
    "is_result = []\n",
    "true_result = 1 - p.cdf(10)\n",
    "Ns = np.logspace(1, 4, num=100)\n",
    "for N in Ns:\n",
    "    # Monte carlo clasico\n",
    "    X = p.rvs(size=int(N))\n",
    "    mc_result.append(np.mean(f(X)))\n",
    "    # Muestreo por importancia\n",
    "    X = q.rvs(size=int(N))\n",
    "    w = p.pdf(X)/q.pdf(X)\n",
    "    is_result.append(np.mean(w*f(X)))\n",
    "# Visualización\n",
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)    \n",
    "ax.plot(Ns, mc_result, label='MC')\n",
    "ax.plot(Ns, is_result, label='IS')\n",
    "ax.axhline(true_result, c='r', ls='--', label='Real')\n",
    "ax.legend()\n",
    "ax.set_ylim([-0.001, true_result*3])\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas de IS\n",
    "\n",
    "Muestreo por importancia y muestreo por rechazo me permiten calcular valores esperados de distribuciones que puedo evaluar pero no muestrear. También vimos que favorece en la disminución de la varianza\n",
    "\n",
    "Pero existen casos más complicados aun, por ejemplo \n",
    "\n",
    "### No puedo muestrear ni evaluar  la distribución de interés\n",
    "\n",
    "Digamos que estamos interesados en la distribución de una variable $\\theta$ condicionada a un conjunto de observaciones $D$, esto corresponde al posterior $p(\\theta|D)$\n",
    "\n",
    "Sólo en contadas ocasiones este posterior corresponderá a una distribución teórica como las que hemos visto en este curso\n",
    "\n",
    "Más en general tendremos\n",
    "\n",
    "$$\n",
    "p(\\theta|x) = \\frac{p(x|\\theta) p(\\theta)}{p(x)}\n",
    "$$\n",
    "\n",
    "donde $p(x|\\theta)$ es la verosimilitud, $p(\\theta)$ es el prior y\n",
    "\n",
    "$$\n",
    "p(x) = \\int_\\theta p(x, \\theta) \\,d\\theta\n",
    "$$\n",
    "\n",
    "es la evidencia o verosimilitud marginal que no depende de $\\theta$. Si la dimensionalidad de $\\theta$ es grande la integral será muy difícil o derechamente imposible de calcular analiticamente. \n",
    "\n",
    "En este caso sólo podemos evaluar la verosimilitud y el prior, es decir que podemos evaluar una distribución proporcional al posterior \n",
    "\n",
    "$$\n",
    "p(\\theta|x) \\propto p(x|\\theta) p(\\theta)\n",
    "$$\n",
    "\n",
    "hasta la constante $1/p(x)$\n",
    "\n",
    "### Espacios demasiado grandes\n",
    "\n",
    "Otro problema de los espacios de alta dimensionalidad es que recorrer ese espacio completo de forma independiente puede ser muy lento o de plano infactible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo MCMC me salva en este caso? Intuición\n",
    "\n",
    "En MCMC en lugar de muestrear de manera iid, utilizamos una cadena de Markov que corresponde a la secuencia de pasos que damos en el espacio de alta dimensionalidad. \n",
    "\n",
    "En la siguiente figura la distribución de interés se muestra de color rojo. En la subfigura de la izquierda usamos una distribución de importancia simple (contorno verde). Muchos de los puntos tendrán un ponderador de importancia cercano a cero. \n",
    "\n",
    "<img src=\"images/is_mcmc.png\" width=\"500\">\n",
    "\n",
    "Los métodos de MCMC se basan en \"diseñar\" esta cadena de Markov tal que converja a la distribución complicada que nos interesa, como muestra la subfigura de la derecha\n",
    "\n",
    "Luego sólo tenemos que dejar que la cadena corra \"por un tiempo largo\" para que la convergencia se cumpla y finalmente usar los valores de los estados de la cadena en representación de la distribución a la cual no tenemos acceso\n",
    "\n",
    "\n",
    "Algunas definiciones:\n",
    "\n",
    "- Esta secuencia de valores se llama **traza**\n",
    "- El tiempo que demora en converger la cadena se llama **mixing time**\n",
    "- Se suele ignorar las primeras muestras de la secuencia puesto que la cadena no ha convergido. Para esto se selecciona un tiempo de **burn-in**. Luego de que se cumpla este tiempo aceptamos las muestras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es diseñar una cadena de Markov?\n",
    "\n",
    "Extendiendo al caso de un estado continuo en lugar de discreto, la distribución estacionaria $\\pi$ debe cumplir\n",
    "\n",
    "$$\n",
    "\\int \\pi(\\theta_t) q(\\theta_{t+1}|\\theta_t) \\,d\\theta_t = \\pi (\\theta_{t+1})\n",
    "$$\n",
    "\n",
    "Diseñar la cadena de Markov consiste en encontrar las probabilidades de transición $q(\\theta_{t+1}|\\theta_t)$ dado que conozco $\\pi$ \n",
    "\n",
    "Notemos que esto es \"al reves\" de lo que hicimos en la lección pasada, que era encontrar $\\pi$ dado que conozco la matriz de transición\n",
    "\n",
    "A continuación veremos veremos que no necesitamos conocer \"completamente\" $\\pi$ para lograr esto, basta conocerlo hasta una constante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Algoritmo de Metropolis\n",
    "\n",
    "El algoritmo de Metropolis fue el primer algoritmo de tipo MCMC. Fue propuesto por Nicholas Metropolis, colega de Ulam y Von Neumann, [en el año 1953 para entender la transición de fase que experimetan los materiales](https://www.semanticscholar.org/paper/Equation-of-state-calculations-by-fast-computing-Metropolis-Rosenbluth/f6a13f116e270dde9d67848495f801cdb8efa25d). En el paper original sentó las bases de lo que hoy conocemos como el algoritmo de Metropolis y el algoritmo de Simulated Annealing (SA)\n",
    "\n",
    "El algoritmo de Metropolis utiliza un random walk para definir las probabilidades de transición de la cadena\n",
    "\n",
    "Sea \n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_{t} + \\epsilon\n",
    "$$\n",
    "\n",
    "donde $\\epsilon$ se distribuye según una distribución centrada en cero y simétrica, muy tipicamente una gaussiana $\\epsilon \\sim \\mathcal{N}(0, I\\sigma_\\epsilon^2)$, donde $\\sigma_\\epsilon$ pasa a ser un hiper parámetro del algoritmo\n",
    "\n",
    "Por definición tenemos entonces \n",
    "\n",
    "$$\n",
    "\\theta^* \\sim q(\\theta_{t+1}|\\theta_{t}) = \\mathcal{N}(\\theta_{t}, I \\sigma_\\epsilon^2)\n",
    "$$\n",
    "\n",
    "La distribución $q$ se denomina **distribución de propuestas** y su objetivo es **proponer** un valor para  $\\theta_{t+1}$ \n",
    "\n",
    "El nuevo valor se acepta con una tasa definida como\n",
    "\n",
    "$$\n",
    "\\alpha(\\theta^*|\\theta_{t}) = \\min(1, r)\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "r = \\frac{ p(\\theta^*)q(\\theta_{t}|\\theta^*) }{ p(\\theta_t)q(\\theta^*|\\theta_{t})} = \\frac{p(\\theta^*)}{p(\\theta_t)}\n",
    "$$\n",
    "\n",
    "donde la última equivalencia se tiene por la simetría\n",
    "\n",
    "Entonces\n",
    "\n",
    "- Si $\\theta^*$ es mucho mejor que $\\theta_t$ entonces se acepta\n",
    "- Si $\\theta^*$ es mucho peor que $\\theta_t$ entonces se rechaza\n",
    "- En caso de duda se deja al azar\n",
    "\n",
    "Respecto de $\\sigma_\\epsilon$\n",
    "- Si su valor es grande tendremos muchos rechazos\n",
    "- Si su valor es pequeño la difusión será lenta y podrían requerirse muchas iteraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalismo\n",
    "\n",
    "El algoritmo completo es\n",
    "\n",
    "\n",
    "- Escoger una distribución de propuestas simétrica \n",
    "- Escoger un valor inicial $\\theta_0$\n",
    "- Para $n=1,2,\\ldots, N$\n",
    "    - Muestrear $\\theta^* \\sim q(\\theta_{t+1}|\\theta_{t})$\n",
    "    - Muestrear $u \\sim U[0, 1]$ \n",
    "    - Luego si \n",
    "    $$\n",
    "    u < \\alpha(\\theta^*|\\theta_{t}) \n",
    "    $$\n",
    "    entonces\n",
    "    $$\n",
    "    \\theta_{t+1} = \\theta^*\n",
    "    $$\n",
    "    de lo contrario\n",
    "    $$\n",
    "    \\theta_{t+1} = \\theta_{t}\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posteriors\n",
    "\n",
    "Notemos que si estamos interesados en un posterior, entonces\n",
    "\n",
    "$$\n",
    "r = \\frac{p(\\theta^*|\\mathcal{D})}{p(\\theta_t|\\mathcal{D})} = \\frac{p(\\mathcal{D}|\\theta^*)p(\\theta^*)}{p(\\mathcal{D}|\\theta_t)p(\\theta_t)} \\frac{p(\\mathcal{D})}{p(\\mathcal{D})} = \\frac{p(\\mathcal{D}|\\theta^*)p(\\theta^*)}{p(\\mathcal{D}|\\theta_t)p(\\theta_t)}\n",
    "$$\n",
    "\n",
    "Es decir que no necesitamos conocer la evidencia o verosimilitud marginal. Basta con conocer la verosimilitud y el prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Sea un conjunto de muestras con $N=5$\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{ 9.37, 10.18, 9.16, 11.60, 10.33 \\}\n",
    "$$\n",
    "\n",
    "que corresponden a realizaciones i.i.d \n",
    "\n",
    "$$\n",
    "X_1, X_2, \\ldots, X_5|\\theta \\sim \\mathcal{N}(\\theta, \\sigma^2=1)\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\mathcal{N}(\\mu=5, \\tau^2=10)\n",
    "$$\n",
    "\n",
    "y nos interesa el posterior $p(\\theta|\\mathcal{D})$\n",
    "\n",
    "En este caso particular el posterior si tiene una forma analítica\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}) = \\mathcal{N}\\left ( \\bar x (1- w_N) + \\mu w_N , \\tau_N^2 \\right)\n",
    "$$\n",
    "\n",
    "donde $w_N = \\tau_N^2/\\tau^2$ y $\\tau_N^2 = (N/\\sigma^2 + 1/\\tau^2)^{-1}$\n",
    "\n",
    "Intentemos simular este posterior con el algoritmo de Metropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([9.37, 10.18, 9.16, 11.60, 10.33])\n",
    "tn2 = (len(x)/1. + 1./10)**(-1)\n",
    "wn = tn2/10.\n",
    "\n",
    "prior = lambda theta : scipy.stats.norm(loc=5, scale=np.sqrt(10)).pdf(theta)\n",
    "likelihood = lambda theta : np.prod([scipy.stats.norm(loc=theta, scale=1.).pdf(x_) for x_ in x])\n",
    "r = lambda ts, tt : likelihood(ts)*prior(ts)/(likelihood(tt)*prior(tt)) \n",
    "\n",
    "def metropolis(mix_time=5000, sigma_eps=1.):\n",
    "    thetas = np.zeros(shape=(mix_time, ))\n",
    "    thetas[0] = np.random.randn()\n",
    "    qs = scipy.stats.norm(loc=0, scale=sigma_eps).rvs(size=mix_time)\n",
    "    us = scipy.stats.uniform.rvs(size=mix_time)\n",
    "    for n in range(1, mix_time):\n",
    "        theta_star = thetas[n-1] + qs[n]    \n",
    "        if us[n] < np.amin([1, r(theta_star, thetas[n-1])]):\n",
    "            thetas[n] = theta_star\n",
    "        else:\n",
    "            thetas[n] = thetas[n-1]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "burn_in = 100\n",
    "thetas = metropolis(mix_time=5000, sigma_eps=1.)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3), tight_layout=True)\n",
    "ax[0].plot(thetas)\n",
    "ax[0].axhline(np.mean(x)*(1-wn) + 5*wn, c='r', ls='--', lw=2, alpha=0.5)\n",
    "ax[1].hist(thetas[burn_in:], density=True, bins=10)\n",
    "t_plot = np.linspace(np.amin(thetas[burn_in:]), \n",
    "                     np.amax(thetas[burn_in:]), num=100)\n",
    "ax[1].plot(t_plot, scipy.stats.norm(loc=np.mean(x)*(1-wn)+5*wn,\n",
    "                                    scale=np.sqrt(tn2)).pdf(t_plot), \n",
    "           c='r', lw=2, ls='--', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propuesto**\n",
    "\n",
    "- Estudie como cambian los resultados con $\\sigma_\\epsilon \\in \\{0.01, 1, 100\\}$\n",
    "- Estudie como cambian los resultados con distintos valores de $\\theta_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Metropolis-Hastings\n",
    "\n",
    "El algoritmo de Metropolis Hastings es una generalización del algoritmo de Metropolis para el caso donde la distribución de propuestas ya no es simétrica por lo que\n",
    "\n",
    "$$\n",
    "r = \\frac{ p(\\theta^*)q(\\theta_{t}|\\theta^*) }{ p(\\theta_t)q(\\theta^*|\\theta_{t})}\n",
    "$$\n",
    "\n",
    "El algoritmo procede de forma idéntica al caso anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
