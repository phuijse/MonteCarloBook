{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repaso de fundamentos \n",
    "\n",
    "## Ley fuerte de los grandes números \n",
    "\n",
    "Sean $X_1, X_2, \\ldots, X_N$ variables aleatorias (V.A.) independientes e idénticamente distribuidas (iid) con \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[X_i] = \\mu\n",
    "$$\n",
    "\n",
    "Se cumple que su promedio\n",
    "\n",
    "$$ \n",
    "\\bar X = \\frac{1}{N} (X_1 + X_2 + \\ldots + X_N) \\to \\mu\n",
    "$$\n",
    "\n",
    "cuando $N \\to \\infty$\n",
    "\n",
    "> El promedio converge al valor esperado con N grande\n",
    "\n",
    "La ley fuerte nos dice que podemos aproximar $\\mu$ con $\\bar X$ pero no nos da pistas sobre que tan cerca está $\\bar X$ de $\\mu$\n",
    "\n",
    "Esto último es importante puesto que en la práctica $N$ nunca será $\\infty$\n",
    "\n",
    "\n",
    "## Teorema central del límite\n",
    "\n",
    "Si $X_1, X_2, \\ldots, X_N$ son V.A iid, entonces su promedio de distribuye como\n",
    "\n",
    "$$ \n",
    "\\bar X \\sim \\mathcal{N}(\\mu, \\sigma^2/N) \n",
    "$$\n",
    "\n",
    "cuando $N \\to \\infty$\n",
    "\n",
    "Es decir que\n",
    "\n",
    "> Cuando N es grande el promedio (suma) se distribuye como una normal centrada en $\\mu$ y con desviación estándar $\\sigma/\\sqrt{N}$\n",
    "\n",
    "Esto ocurre sin importar la distribución original de las V.A., pero tienen que ser independientes!\n",
    "\n",
    "Más importante aun\n",
    "\n",
    "> La tasa a la que converge el estimador a su valor esperado es $\\frac{1}{\\sqrt{N}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: La distribución del promedio de lanzar $n$ dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3), tight_layout=True)\n",
    "\n",
    "def update_plot(k):\n",
    "    ax.cla()\n",
    "    ax.set_title(\"Promedio de {0} lanzamiento/s de dado\".format(k+1))\n",
    "    dist = scipy.stats.multinomial(n=k+1, p=[1/6]*6)\n",
    "    repeats = dist.rvs(size=1000)\n",
    "    average_dice = np.sum(repeats*range(1, 7)/(k+1), axis=1)\n",
    "    ax.hist(average_dice, bins=12, density=True)\n",
    "    ax.set_xlim([1, 6])\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=15, interval=1000, \n",
    "                               repeat=True, blit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integración por Monte Carlo\n",
    "\n",
    "La integración por Monte Carlo consiste en estimar el valor esperado de una función $g(x)$, definido como\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[g(X)] = \\int g(x) f(x) \\,dx\n",
    "$$\n",
    "\n",
    "donde $f(x)$ es la densidad de $x$\n",
    "\n",
    "por medio de\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[g(X)] \\approx \\hat g_N = \\frac{1}{N} \\sum_{i=1}^N g(x_i) \\quad x_i \\sim f(x)\n",
    "$$\n",
    "\n",
    "Por otro lado el teorema central del límite nos asegura que\n",
    "\n",
    "$$\n",
    "\\hat g_N \\sim \\mathcal{N} \\left( \\mathbb{E}[g(X)], \\sigma_N^2/N \\right)\n",
    "$$\n",
    "\n",
    "donde la varianza muestreal se puede estimar como\n",
    "\n",
    "$$\n",
    "\\sigma_N^2 = \\frac{1}{N-1} \\sum_{i=1}^N (g(x_i) - \\hat g_N)^2 \n",
    "$$\n",
    "\n",
    "> En resumen el estimador converge a su valor esperado a una tasa de $\\frac{1}{\\sqrt{N}}$. Esto es independiente de la dimensionalidad de la integral. Es decir que para una integral complicada con muchas dimensiones Monte Carlo puede darnos muchas ventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadenas de Markov\n",
    "\n",
    "En la lección anterior vimos la definición de un proceso estocástico\n",
    "\n",
    "En lo que sigue asumiremos que el proceso estocástico solo puede tomar valores de un conjunto discreto $\\mathcal{S}$ en tiempos $n>0$ que también son discretos\n",
    "\n",
    "Llamaremos a $\\mathcal{S}=\\{1, 2, \\ldots, M\\}$ el conjunto de **estados** del proceso y cada estado en particular se suele denotar por un número natural\n",
    "\n",
    "Para que un proceso estocástico sea considerado una **cadena de Markov**  se debe cumplir \n",
    "\n",
    "$$\n",
    "P(X_{n+1}|X_{n}, X_{n-1}, \\ldots, X_{1}) = P(X_{n+1}|X_{n})\n",
    "$$\n",
    "\n",
    "que se conoce como la propiedad de Markov o propiedad markoviana\n",
    "\n",
    "> El estado futuro es independiente del pasado dado el presente\n",
    "\n",
    "En particular si la cadena de Markov tiene estados discretos y es homogenea, podemos escribir\n",
    "\n",
    "$$\n",
    "P(X_{n+1}=j|X_{n}=i) = P_{ij},\n",
    "$$\n",
    "\n",
    "donde homogeneo quiere decir que la probabilidad de transicionar de un estado a otro no cambia con el tiempo\n",
    "\n",
    "La probabilidad $P_{i,j}$ se suele llamar probabilidad de transición \"a un paso\"\n",
    "\n",
    "El conjunto con todas las posibles combinaciones $P_{ij}$ para $i,j \\in \\mathcal{S}$ forma una matriz cuadrada de $M \\times M$ que se conoce como matriz de transición\n",
    "\n",
    "$$\n",
    "P = \\begin{pmatrix} P_{11} & P_{12} & \\ldots & P_{1M} \\\\ \n",
    "P_{21} & P_{22} & \\ldots & P_{2M} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "P_{M1} & P_{M2} & \\ldots & P_{MM}\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Donde siempre se debe cumplir que las filas sumen 1\n",
    "\n",
    "$$\n",
    "\\sum_{j \\in \\mathcal{S}} P_{ij} = 1\n",
    "$$\n",
    "\n",
    "\n",
    "Además todos los $P_{ij} \\geq 0$  y $P_{ij} \\in [0, 1]$\n",
    "\n",
    "\n",
    "Una matriz de transición o matriz estocástica puede representarse como un grafo dirigido donde los vertices son los estados y las aristas las probabilidades de transición o pesos\n",
    "\n",
    "El siguiente es un ejemplo de grafo para un sistema de cuatro estados con todas sus transiciones equivalentes e iguales a $1/2$. Las transiciones con probabilidad $0$ no se muestran.\n",
    "\n",
    "<img src=\"images/markov2.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere ahora el siguiente ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/markov-ruin.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que si salimos del estado $0$ o del estado $3$ ya no podemos volver a ellos. Esto se conoce como un estado **transitorio** o transiente\n",
    "\n",
    "Por el contrario los estados a los que si tenemos posibilidad de retornar se llaman estados **recurrentes**\n",
    "\n",
    "Cuando se tienen estados a los que no se puede retornar se dice que cadena es **reducible**\n",
    "\n",
    "Por el contrario si podemos regresar a todos los estados se dice que la cadena es **irreducible**\n",
    "\n",
    "Una cadena reducible puede \"dividirse\" para crear cadenas irreducibles. En el ejemplo de arriba podemos separar $\\{0\\}$, $\\{1,2\\}$ y $\\{3\\}$ en tres cadenas irreducibles\n",
    "\n",
    "La cadena de Markov anterior modela un problema conocido como la ruina del apostador, puedes estudiar de que se trata [aquí](https://en.wikipedia.org/wiki/Gambler%27s_ruin) y [aquí](http://manjeetdahiya.com/posts/markov-chains-gamblers-ruin/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Cadena de dos estados\n",
    "\n",
    "Digamos que queremos predecir el clima de Valdivia por medio de un modelo de cadena de Markov\n",
    "\n",
    "Asumiremos que el clima de mañana es perfectamente predecible a partir del clima de hoy\n",
    "\n",
    "Sean dos estados\n",
    "\n",
    "- $s_A$ Luvioso\n",
    "- $s_B$ Soleado\n",
    "\n",
    "Con probabilidades condicionales $P(s_A|s_A) = 0.7$, $P(s_B|s_A) = 0.3$, $P(s_A|s_B) = 0.45$ y $P(s_B|s_B) = 0.55$\n",
    "\n",
    "En este caso la matriz de transición de la cadena es\n",
    "\n",
    "$$ \n",
    "P = \\begin{pmatrix} P(s_A|s_A) & P(s_B|s_A) \\\\ P(s_A|s_B) & P(s_B|s_B) \\end{pmatrix}  = \\begin{pmatrix} 0.7 & 0.3 \\\\ 0.45 & 0.55 \\end{pmatrix} \n",
    "$$\n",
    "\n",
    "que también se puede visualizar como un mapa de transición\n",
    "\n",
    "<img src=\"images/markov1.png\" width=\"600\">\n",
    "\n",
    "Si está soleado hoy, ¿Cuál es la probabilidad de que llueva mañana, en tres dias más y en una semana más? \n",
    "\n",
    "Podemos usar la matriz de transición para responder esta pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "P = np.array([[0.70, 0.30],\n",
    "              [0.45, 0.55]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear un vector de estado como un arreglo con codificación `one-hot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s0 = np.array([0, 1]) # Estado soleado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, las probabilidades para mañana dado que hoy esta soleado puede calcularse como\n",
    "\n",
    "$$\n",
    "s_1 = s_0 P\n",
    "$$\n",
    "\n",
    "que se conoce como transición a un paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(s0, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad para tres días más puede calcularse como\n",
    "\n",
    "$$\n",
    "s_3 = s_2 P = s_1 P^2 = s_0 P^3\n",
    "$$\n",
    "\n",
    "que se conoce como transición a 3 pasos\n",
    "\n",
    "Sólo necesitamos elevar la matriz al cubo y multiplicar por el estado inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(s0, np.linalg.matrix_power(P, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El pronóstico para una semana sería entonces la transición a 7 pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(s0, np.linalg.matrix_power(P, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que el estado de nuestro sistema comienza a converger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(s0, np.linalg.matrix_power(P, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estado estacionario de la cadena de Markov\n",
    "\n",
    "Si la cadena de Markov converge a un estado, ese estado se llama **estado estacionario**\n",
    "\n",
    "Una cadena puede tener más de un estado estacionario\n",
    "\n",
    "Por definición en un estado estacionario se cumple que \n",
    "\n",
    "$$\n",
    "s P = s\n",
    "$$\n",
    "\n",
    "Que corresponde al problema de valores y vectores propios\n",
    "\n",
    "> Es decir que los estados estacionarios son los vectores propios del sistema\n",
    "\n",
    "\n",
    "Para el ejemplo anterior teniamos que\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} s_1 & s_2 \\end{pmatrix} P = \\begin{pmatrix} s_1 & s_2 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Que resulta en las siguientes ecuaciones\n",
    "\n",
    "$$\n",
    "0.7 s_1 + 0.45 s_2 = s_1 \n",
    "$$\n",
    "\n",
    "$$\n",
    "0.3 s_1 + 0.55 s_2 = s_2\n",
    "$$\n",
    "\n",
    "Ambas nos dicen que $s_2 = \\frac{2}{3} s_1$, si además consideramos que $s_1 + s_2 = 1$ podemos despejar y obtener\n",
    "\n",
    "- $s_1 = 3/5 = 0.6$\n",
    "- $s_2 = 0.4$\n",
    "\n",
    "Que es lo que vimos antes\n",
    "\n",
    "Esto nos dice que el 60\\% de los días va a llover y un 40\\% estará soleado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transición de n-pasos\n",
    "\n",
    "Una pregunta interesante a responder con una cadena de Markov es\n",
    "\n",
    "¿Cuál es la probabilidad de llegar al estado $j$ dado que estoy en el estado $i$ si doy exactamente $n$ pasos?\n",
    "\n",
    "Consideremos por ejemplo \n",
    "\n",
    "<img src=\"images/markov3.png\" width=\"400\">\n",
    "\n",
    "donde la matriz de transición es claramente\n",
    "\n",
    "$$\n",
    "P = \\begin{pmatrix} 1/2 & 1/4 & 1/4 \\\\ \n",
    "1/4 & 1/2 & 1/4 \\\\\n",
    "1/4 & 1/4 & 1/2\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "- ¿Cuántos caminos hay para llegar a $2$ desde $0$ en 2 pasos?\n",
    "- ¿Cuál es la probabilidad asociada?\n",
    "\n",
    "$$\n",
    "0.3125 = P_{00}P_{02} + P_{01}P_{12} + P_{02}P_{22} = \\begin{pmatrix} P_{00}  & P_{01} & P_{02} \\end{pmatrix} \\begin{pmatrix} P_{02} \\\\ P_{12} \\\\ P_{22} \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuántos caminos hay para llegar a $0$ desde $0$ en 2 pasos?\n",
    "- ¿Cuál es la probabilidad asociada?\n",
    "\n",
    "$$\n",
    "0.375 = P_{00}P_{00} + P_{01}P_{10} + P_{02}P_{20} = \\begin{pmatrix} P_{00}  & P_{01} & P_{02} \\end{pmatrix} \\begin{pmatrix} P_{00} \\\\ P_{10} \\\\ P_{20} \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([[1/2, 1/4, 1/4],\n",
    "              [1/4, 1/2, 1/4],\n",
    "              [1/4, 1/4, 1/2]])\n",
    "\n",
    "np.dot(P, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de llegar al estado $j$ desde el estado $i$ en $n$ pasos es equivalente al elemento en la fila $i$ y columna $j$ de la matriz $P^n$\n",
    "\n",
    "¿Qué ocurre cuando $n$ tiene a infinito?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(np.linalg.matrix_power(P, 3),\n",
    "      np.linalg.matrix_power(P, 5),\n",
    "      np.linalg.matrix_power(P, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las filas convergen al mismo valor, esto se conoce como la distribución estacionaria de la cadena de Markov\n",
    "\n",
    "$P_{ij}^\\infty$ nos da la probabilidad de estar en $j$ luego de infinitos pasos\n",
    "\n",
    "El punto de partida ya no tiene relevancia\n",
    "\n",
    "Las filas de $P^\\infty$ convergen solo si la cadena es irreducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo general para simular una cadena de Markov discreta\n",
    "\n",
    "Asumiendo que tenemos un sistema con un conjunto discreto de estados $\\mathcal{S}$ estados y que conocemos la matriz de probabilidades de transición $P$ podemos simular su evolución con el siguiente algoritmo\n",
    "\n",
    "1. Setear $n=0$ y seleccionar un estado inicial $X_n = i$\n",
    "1. Para $n = 1,2,\\ldots,T$\n",
    "    1. Obtener la fila de $P$ que corresponde al estado actual $X_n$, es decir $P[X_n, :]$\n",
    "    1. Generar $X_{n+1}$ de una distribución multinomial con vector de probabilidad igual a la fila seleccionada \n",
    "\n",
    "En este caso $T$ es el horizonte de la simulación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulando una variable aleatoria multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.multinomial.rvs(n=1, p=[0.7, 0.2, 0.1], size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando el argumento máximo de 100 realizaciones y graficando el histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 3), tight_layout=True)\n",
    "ax.hist(np.argmax(scipy.stats.multinomial.rvs(n=1, p=[0.7, 0.2, 0.1], size=100), axis=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulando 1000 cadenas a un horizonte de 10 pasos para el ejemplo de dos estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([[0.70, 0.30],\n",
    "              [0.45, 0.55]])\n",
    "\n",
    "n_chains = 10000\n",
    "horizon = 10\n",
    "states = np.zeros(shape=(n_chains, horizon), dtype='int')\n",
    "states[:, 0] = 1\n",
    "for i in range(n_chains):\n",
    "    for j in range(1, horizon):\n",
    "        states[i, j] = np.argmax(scipy.stats.multinomial.rvs(n=1, p=P[states[i, j-1], :], size=1))\n",
    "        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)\n",
    "for i in range(3):\n",
    "    ax.plot(states[i, :], '-o', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = len(np.unique(states))\n",
    "\n",
    "hist = np.zeros(shape=(horizon, n_states))\n",
    "for j in range(horizon):\n",
    "    hist[j, :] = np.array([sum(states[:, j] == s) for s in range(n_states)])\n",
    "\n",
    "print(hist)\n",
    "fig, ax = plt.subplots(figsize=(4, 3), tight_layout=True)\n",
    "ax.plot(np.argmax(hist, axis=1), marker='x')\n",
    "ax.axhline(1, ls='--', c='k', alpha=0.5)\n",
    "ax.axhline(0, ls='--', c='k', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Más sobre cadenas de Markov\n",
    "\n",
    "https://www.uni-ulm.de/fileadmin/website_uni_ulm/mawi.inst.110/lehre/ss17/Stochastic_Simulation/Lecture_Notes_01.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
