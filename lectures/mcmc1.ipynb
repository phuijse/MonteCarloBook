{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo (MCMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las cadenas de Markov tienen dos usos principales\n",
    "\n",
    "En primer lugar las cadenas de Markov se ocupan como **modelo o aproximación de fenómenos que evolucionan en el tiempo**. Esto es lo que vimos la lección anterior.\n",
    "\n",
    "En estos casos corresponde hacer la pregunta empírica de si acaso el fenómeno que estoy estudiando cumple con la propiedad de Markov. Por ejemplo ¿Es la evolución del clima un proceso de Markov?\n",
    "\n",
    "En segundo lugar las cadenas de Markov son un **componente fundamental de una clase de algoritmos conocidos como Markov Chain Monte Carlo** (MCMC)\n",
    "\n",
    "El objetivo de MCMC es crear sintéticamente una cadena de Markov que converge a una distribución en la cual estamos interesados y que no podemos simular de forma analítica y/o explícita\n",
    "\n",
    "MCMC es considerado una revolución en computación científica y es usado en prácticamente todos las disciplinas. \n",
    "\n",
    "En esta lección estudiaremos el algoritmos de Metropolis, una de las formulaciones originales de MCMC y también uno de los [diez algoritmos más importantes del Siglo XX](https://www.andrew.cmu.edu/course/15-355/misc/Top%20Ten%20Algorithms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC es una poderosa herramienta para muestrear y calcular valores esperados a partir de distribuciones complejas \n",
    "\n",
    "En este sentido es una extensión de la idea básica de Monte Carlo que vimos en las primeras lecciones\n",
    "\n",
    "## Monte Carlo y muestreo por importancia (IS)\n",
    "\n",
    "Sea una función $f()$ sobre una variable aleatoria con distribución $p(x)$\n",
    "\n",
    "Con Monte Carlo puedo estimar el valor esperado de esta función en base a muestras usando \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[f(X)] \\approx \\frac{1}{N} \\sum_{i=1}^N f(x_i) \\quad x_i \\sim p(x)\n",
    "$$\n",
    "\n",
    "Siempre y cuando yo pueda muestrear directamente de $p(x)$\n",
    "\n",
    "Si no puedo muestrear de $p(x)$ pero si es posible evaluarla, puedo recurrir a la técnica de muestreo por importancia (IS) que se define a cotninuación\n",
    "\n",
    "Sea una distribución de propuestas o distribución de importancia $q(x)$ de la cual yo puedo evaluar y además muestrear \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{x\\sim p(x)}[f(X)] &= \\int p(x) f(x) \\,dx = \\int q(x)  \\frac{p(x)}{q(x)} f(x) \\,dx \\nonumber \\\\\n",
    "&= \\mathbb{E}_{x\\sim q(x)}\\left[ \\frac{p(x)}{q(x)} f(X)\\right] \\nonumber \\\\\n",
    "&\\approx \\frac{1}{N} \\sum_{i=1}^N w_i f(x_i) \\quad x_i \\sim q(x) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $w_i = \\frac{p(x)}{q(x)}$ se llama la ponderación de importancia. \n",
    "\n",
    "Una distribución de importancia correcta no sólo nos permite resolver el problema sino que tiende a tener una varianza más baja que el estimador original de Monte Carlo. No es necesario escoger una distribución de importancia que sea igual a la distribución original, pero se debe tener en cuanta que que $q(x)$ debe ser tal que $p(x)=0$ cuando $q(x)=0$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Sea una linea de teléfono de soporte tecnológico que recibe en promedio 2 llamadas por minuto\n",
    "\n",
    "¿Cuál es la probabilidad de que ellos tengan que esperar por lo menos 10 minutos para recibir 9 llamadas?\n",
    "\n",
    "Usemos una simulación para resolver este problema\n",
    "\n",
    "Note como el estimador basado en IS converge más rápido y con menos varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2. # Eventos promedio por minuto\n",
    "a = 9 # Cantidad de eventos\n",
    "# La distribución gamma modela tiempos de espera para una cierta cantidad de eventos\n",
    "p = scipy.stats.gamma(a, scale=1/b) \n",
    "# La función f en esta caso me dice \n",
    "f = lambda x: x > 10\n",
    "# La función de propuesta\n",
    "q = scipy.stats.norm(scale=10)\n",
    "# Simulación\n",
    "mc_result = []\n",
    "is_result = []\n",
    "true_result = 1 - p.cdf(10)\n",
    "Ns = np.logspace(1, 4, num=100)\n",
    "for N in Ns:\n",
    "    # Monte carlo clasico\n",
    "    X = p.rvs(size=int(N))\n",
    "    mc_result.append(np.mean(f(X)))\n",
    "    # Muestreo por importancia\n",
    "    X = q.rvs(size=int(N))\n",
    "    w = p.pdf(X)/q.pdf(X)\n",
    "    is_result.append(np.mean(w*f(X)))\n",
    "# Visualización\n",
    "fig, ax = plt.subplots(figsize=(6, 3), tight_layout=True)    \n",
    "ax.plot(Ns, mc_result, label='MC')\n",
    "ax.plot(Ns, is_result, label='IS')\n",
    "ax.axhline(true_result, c='r', ls='--', label='Real')\n",
    "ax.legend()\n",
    "ax.set_ylim([-0.001, true_result*3])\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas de IS\n",
    "\n",
    "Muestreo por importancia y muestreo por rechazo me permiten calcular valores esperados de distribuciones que puedo evaluar pero no muestrear. También vimos que favorece en la disminución de la varianza\n",
    "\n",
    "Pero existen casos más complicados aun, por ejemplo \n",
    "\n",
    "### No puedo muestrear ni evaluar  la distribución de interés\n",
    "\n",
    "Digamos que estamos interesados en la distribución de una variable $\\theta$ condicionada a un conjunto de observaciones $D$, esto corresponde al posterior $p(\\theta|D)$\n",
    "\n",
    "Sólo en contadas ocasiones este posterior corresponderá a una distribución teórica como las que hemos visto en este curso\n",
    "\n",
    "Más en general tendremos\n",
    "\n",
    "$$\n",
    "p(\\theta|x) = \\frac{p(x|\\theta) p(\\theta)}{p(x)}\n",
    "$$\n",
    "\n",
    "donde $p(x|\\theta)$ es la verosimilitud, $p(\\theta)$ es el prior y\n",
    "\n",
    "$$\n",
    "p(x) = \\int_\\theta p(x, \\theta) \\,d\\theta\n",
    "$$\n",
    "\n",
    "es la evidencia o verosimilitud marginal que no depende de $\\theta$. Si la dimensionalidad de $\\theta$ es grande la integral será muy difícil o derechamente imposible de calcular analiticamente. \n",
    "\n",
    "En este caso sólo podemos evaluar la verosimilitud y el prior, es decir que podemos evaluar una distribución proporcional al posterior \n",
    "\n",
    "$$\n",
    "p(\\theta|x) \\propto p(x|\\theta) p(\\theta)\n",
    "$$\n",
    "\n",
    "hasta la constante $1/p(x)$\n",
    "\n",
    "### Espacios demasiado grandes\n",
    "\n",
    "Otro problema de los espacios de alta dimensionalidad es que recorrer ese espacio completo de forma independiente puede ser muy lento o de plano infactible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo MCMC me salva en este caso? Intuición\n",
    "\n",
    "En MCMC en lugar de muestrear de manera iid, utilizamos una cadena de Markov que corresponde a la secuencia de pasos que damos en el espacio de alta dimensionalidad. \n",
    "\n",
    "En la siguiente figura la distribución de interés se muestra de color rojo. En la subfigura de la izquierda usamos una distribución de importancia simple (contorno verde). Muchos de los puntos tendrán un ponderador de importancia cercano a cero. \n",
    "\n",
    "<img src=\"images/is_mcmc.png\" width=\"500\">\n",
    "\n",
    "Los métodos de MCMC se basan en \"diseñar\" esta cadena de Markov tal que converja a la distribución complicada que nos interesa, como muestra la subfigura de la derecha\n",
    "\n",
    "Luego sólo tenemos que dejar que la cadena corra \"por un tiempo largo\" para que la convergencia se cumpla y finalmente usar los valores de los estados de la cadena en representación de la distribución a la cual no tenemos acceso\n",
    "\n",
    "\n",
    "Algunas definiciones:\n",
    "\n",
    "- Esta secuencia de valores se llama **traza**\n",
    "- El tiempo que demora en converger la cadena se llama **mixing time**\n",
    "- Se suele ignorar las primeras muestras de la secuencia puesto que la cadena no ha convergido. Para esto se selecciona un tiempo de **burn-in**. Luego de que se cumpla este tiempo aceptamos las muestras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es diseñar una cadena de Markov?\n",
    "\n",
    "Extendiendo al caso de un estado continuo en lugar de discreto, la distribución estacionaria $\\pi$ debe cumplir\n",
    "\n",
    "$$\n",
    "\\int \\pi(\\theta_t) q(\\theta_{t+1}|\\theta_t) \\,d\\theta_t = \\pi (\\theta_{t+1})\n",
    "$$\n",
    "\n",
    "Diseñar la cadena de Markov consiste en encontrar las probabilidades de transición $q(\\theta_{t+1}|\\theta_t)$ dado que conozco $\\pi$ \n",
    "\n",
    "Notemos que esto es \"al reves\" de lo que hicimos en la lección pasada, que era encontrar $\\pi$ dado que conozco la matriz de transición\n",
    "\n",
    "A continuación veremos veremos que no necesitamos conocer \"completamente\" $\\pi$ para lograr esto, basta conocerlo hasta una constante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Algoritmo de Metropolis\n",
    "\n",
    "El algoritmo de Metropolis fue el primer algoritmo de tipo MCMC. Fue propuesto por Nicholas Metropolis, colega de Ulam y Von Neumann, [en el año 1953 para entender la transición de fase que experimetan los materiales](https://www.semanticscholar.org/paper/Equation-of-state-calculations-by-fast-computing-Metropolis-Rosenbluth/f6a13f116e270dde9d67848495f801cdb8efa25d). En el paper original sentó las bases de lo que hoy conocemos como el algoritmo de Metropolis y el algoritmo de Simulated Annealing (SA)\n",
    "\n",
    "El algoritmo de Metropolis utiliza un random walk para definir las probabilidades de transición de la cadena\n",
    "\n",
    "Sea \n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_{t} + \\epsilon\n",
    "$$\n",
    "\n",
    "donde $\\epsilon$ se distribuye según una distribución centrada en cero y simétrica, muy tipicamente una gaussiana $\\epsilon \\sim \\mathcal{N}(0, I\\sigma_\\epsilon^2)$, donde $\\sigma_\\epsilon$ pasa a ser un hiper parámetro del algoritmo\n",
    "\n",
    "Por definición tenemos entonces \n",
    "\n",
    "$$\n",
    "\\theta^* \\sim q(\\theta_{t+1}|\\theta_{t}) = \\mathcal{N}(\\theta_{t}, I \\sigma_\\epsilon^2)\n",
    "$$\n",
    "\n",
    "La distribución $q$ se denomina **distribución de propuestas** y su objetivo es **proponer** un valor para  $\\theta_{t+1}$ \n",
    "\n",
    "El nuevo valor se acepta con una tasa definida como\n",
    "\n",
    "$$\n",
    "\\alpha(\\theta^*|\\theta_{t}) = \\min(1, r)\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "r = \\frac{ p(\\theta^*)q(\\theta_{t}|\\theta^*) }{ p(\\theta_t)q(\\theta^*|\\theta_{t})} = \\frac{p(\\theta^*)}{p(\\theta_t)}\n",
    "$$\n",
    "\n",
    "donde la última equivalencia se tiene por la simetría\n",
    "\n",
    "Entonces\n",
    "\n",
    "- Si $\\theta^*$ es mucho mejor que $\\theta_t$ entonces se acepta\n",
    "- Si $\\theta^*$ es mucho peor que $\\theta_t$ entonces se rechaza\n",
    "- En caso de duda se deja al azar\n",
    "\n",
    "Respecto de $\\sigma_\\epsilon$\n",
    "- Si su valor es grande tendremos muchos rechazos\n",
    "- Si su valor es pequeño la difusión será lenta y podrían requerirse muchas iteraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalismo\n",
    "\n",
    "El algoritmo completo es\n",
    "\n",
    "\n",
    "- Escoger una distribución de propuestas simétrica \n",
    "- Escoger un valor inicial $\\theta_0$\n",
    "- Para $n=1,2,\\ldots, N$\n",
    "    - Muestrear $\\theta^* \\sim q(\\theta_{t+1}|\\theta_{t})$\n",
    "    - Muestrear $u \\sim U[0, 1]$ \n",
    "    - Luego si \n",
    "    $$\n",
    "    u < \\alpha(\\theta^*|\\theta_{t}) \n",
    "    $$\n",
    "    entonces\n",
    "    $$\n",
    "    \\theta_{t+1} = \\theta^*\n",
    "    $$\n",
    "    de lo contrario\n",
    "    $$\n",
    "    \\theta_{t+1} = \\theta_{t}\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posteriors\n",
    "\n",
    "Notemos que si estamos interesados en un posterior, entonces\n",
    "\n",
    "$$\n",
    "r = \\frac{p(\\theta^*|\\mathcal{D})}{p(\\theta_t|\\mathcal{D})} = \\frac{p(\\mathcal{D}|\\theta^*)p(\\theta^*)}{p(\\mathcal{D}|\\theta_t)p(\\theta_t)} \\frac{p(\\mathcal{D})}{p(\\mathcal{D})} = \\frac{p(\\mathcal{D}|\\theta^*)p(\\theta^*)}{p(\\mathcal{D}|\\theta_t)p(\\theta_t)}\n",
    "$$\n",
    "\n",
    "Es decir que no necesitamos conocer la evidencia o verosimilitud marginal. Basta con conocer la verosimilitud y el prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Sea un conjunto de muestras con $N=5$\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{ 9.37, 10.18, 9.16, 11.60, 10.33 \\}\n",
    "$$\n",
    "\n",
    "que corresponden a realizaciones i.i.d \n",
    "\n",
    "$$\n",
    "X_1, X_2, \\ldots, X_5|\\theta \\sim \\mathcal{N}(\\theta, \\sigma^2=1)\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\mathcal{N}(\\mu=5, \\tau^2=10)\n",
    "$$\n",
    "\n",
    "y nos interesa el posterior $p(\\theta|\\mathcal{D})$\n",
    "\n",
    "En este caso particular el posterior si tiene una forma analítica\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}) = \\mathcal{N}\\left ( \\bar x (1- w_N) + \\mu w_N , \\tau_N^2 \\right)\n",
    "$$\n",
    "\n",
    "donde $w_N = \\tau_N^2/\\tau^2$ y $\\tau_N^2 = (N/\\sigma^2 + 1/\\tau^2)^{-1}$\n",
    "\n",
    "Intentemos simular este posterior con el algoritmo de Metropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([9.37, 10.18, 9.16, 11.60, 10.33])\n",
    "tn2 = (len(x)/1. + 1./10)**(-1)\n",
    "wn = tn2/10.\n",
    "\n",
    "prior = lambda theta : scipy.stats.norm(loc=5, scale=np.sqrt(10)).pdf(theta)\n",
    "likelihood = lambda theta : np.prod([scipy.stats.norm(loc=theta, scale=1.).pdf(x_) for x_ in x])\n",
    "r = lambda ts, tt : likelihood(ts)*prior(ts)/(likelihood(tt)*prior(tt)) \n",
    "\n",
    "def metropolis(mix_time=5000, sigma_eps=1.):\n",
    "    thetas = np.zeros(shape=(mix_time, ))\n",
    "    thetas[0] = np.random.randn()\n",
    "    qs = scipy.stats.norm(loc=0, scale=sigma_eps).rvs(size=mix_time)\n",
    "    us = scipy.stats.uniform.rvs(size=mix_time)\n",
    "    for n in range(1, mix_time):\n",
    "        theta_star = thetas[n-1] + qs[n]    \n",
    "        if us[n] < np.amin([1, r(theta_star, thetas[n-1])]):\n",
    "            thetas[n] = theta_star\n",
    "        else:\n",
    "            thetas[n] = thetas[n-1]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "burn_in = 100\n",
    "thetas = metropolis(mix_time=5000, sigma_eps=1.)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3), tight_layout=True)\n",
    "ax[0].plot(thetas)\n",
    "ax[0].axhline(np.mean(x)*(1-wn) + 5*wn, c='r', ls='--', lw=2, alpha=0.5)\n",
    "ax[1].hist(thetas[burn_in:], density=True, bins=10)\n",
    "t_plot = np.linspace(np.amin(thetas[burn_in:]), \n",
    "                     np.amax(thetas[burn_in:]), num=100)\n",
    "ax[1].plot(t_plot, scipy.stats.norm(loc=np.mean(x)*(1-wn)+5*wn,\n",
    "                                    scale=np.sqrt(tn2)).pdf(t_plot), \n",
    "           c='r', lw=2, ls='--', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propuesto**\n",
    "\n",
    "- Estudie como cambian los resultados con $\\sigma_\\epsilon \\in \\{0.01, 1, 100\\}$\n",
    "- Estudie como cambian los resultados con distintos valores de $\\theta_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Metropolis-Hastings\n",
    "\n",
    "El algoritmo de Metropolis Hastings es una generalización del algoritmo de Metropolis para el caso donde la distribución de propuestas ya no es simétrica por lo que\n",
    "\n",
    "$$\n",
    "r = \\frac{ p(\\theta^*)q(\\theta_{t}|\\theta^*) }{ p(\\theta_t)q(\\theta^*|\\theta_{t})}\n",
    "$$\n",
    "\n",
    "El algoritmo procede de forma idéntica al caso anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
