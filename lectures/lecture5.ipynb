{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiempo de mezcla (mixing time)\n",
    "\n",
    "Previamente hemos visto como diseñar una cadena de Markov finita tal que converja a una distribución estacionaria de nuestro interés\n",
    "\n",
    "Pero ¿Cuánto debemos esperar para que ocurra la convergencia? \n",
    "\n",
    "El tiempo de mezcla para una cadena de Markov irreducible y aperiodica se define como\n",
    "\n",
    "$$\n",
    "t_{mix}(\\epsilon) = \\min \\left(n > 0: \\|s(n) - \\pi\\|_{TV} < \\epsilon \\right)\n",
    "$$\n",
    "\n",
    "es decir el mínimo tiempo (número de pasos) tal que estemos a una distancia $\\epsilon$ de la distribución estacionaria $\\pi$\n",
    "\n",
    "El operador $\\|p - q\\|_{TV} = \\max_{x\\in\\mathcal{\\Omega}} \\|p(x) - q(x)\\|$ se conoce como la distancia de variación total entre dos distribuciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tienen algunas garantías con respecto a este tiempo, en particular la siguiente cota superior\n",
    "\n",
    "$$\n",
    "t_{mix}(\\epsilon) < \\log \\left(\\frac{1}{\\epsilon \\sqrt{\\min_j \\pi_j}} \\right) \\frac{1}{1-\\lambda_*} \n",
    "$$\n",
    "\n",
    "donde $\\lambda_*$ es el segundo valor propio más grande de la matriz de transición $P$ de la cadena. \n",
    "\n",
    "La descomposición en valores propios de la matriz de transición de una cadena irreducible y de $\\mathcal{S}$ estados se puede escribir como\n",
    "\n",
    "$$\n",
    "P^n = \\sum_{i=1}^\\mathcal{S} \\alpha_i \\lambda_i^n = \\pi + \\sum_{i=2}^\\mathcal{S} \\alpha_i \\lambda_i^n\n",
    "$$\n",
    "\n",
    "Por propiedad de la cadena de Markov irreducible su valor propio más grande siempre es igual a uno y su vector propio asociado es la distribución estacionaria. \n",
    "\n",
    "Todos los demás valores propios se harán eventualmente cero cuando $n \\to \\infty$, siendo el segundo valor propio más grande y distinto de uno el que más se demore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelación en la cadena y número de muestras efectivo\n",
    "\n",
    "¿Cómo podemos confirmar si nuestro algoritmo MCMC ha convergido? \n",
    "\n",
    "Por construcción, las muestras de nuestra traza son dependientes, pues $\\theta_{t+1}$ se calcula a partir de $\\theta_t$. \n",
    "\n",
    "Sin embargo, luego de un periódo de *burn-in*, las probabilidades de transición de la cadena debería converger a la distribución estacionaria y volverse independientes del tiempo\n",
    "\n",
    "Es decir que podemos confirmar la convergencia estudiando la autocorrelación de la traza\n",
    "\n",
    "$$\n",
    "\\rho(\\tau) = \\mathbb{E}\\left[(\\theta_t - \\bar \\theta)(\\theta_{t+\\tau}  - \\bar \\theta)\\right]\n",
    "$$\n",
    "\n",
    "La autocorrelación nos indica que tanto las muestras de una serie de tiempo dependen de muestras pasadas. \n",
    "\n",
    "\n",
    "En este caso, al graficar $\\rho$ en función de $\\tau$ buscamos una autocorrelación que converja rapidamente y que luego fluctue en torno a cero\n",
    "\n",
    "<img src=\"images/autocorr.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "\n",
    "La lección pasada vimos como el valor de $\\sigma_\\epsilon$ repercutía fuertemente en la convergencia del algoritmo de Metropolis\n",
    "\n",
    "Usemos la función `np.correlate` para estudiar la autocorrelación de las trazas para distintos valores de $\\sigma_\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([9.37, 10.18, 9.16, 11.60, 10.33])\n",
    "\n",
    "prior = lambda theta : scipy.stats.norm(loc=5, scale=np.sqrt(10)).pdf(theta)\n",
    "likelihood = lambda theta : np.prod([scipy.stats.norm(loc=theta, scale=1.).pdf(x_) for x_ in x])\n",
    "r = lambda ts, tt : likelihood(ts)*prior(ts)/(likelihood(tt)*prior(tt)) \n",
    "\n",
    "def metropolis(mix_time=5000, sigma_eps=1.):\n",
    "    thetas = np.zeros(shape=(mix_time, ))\n",
    "    thetas[0] = np.random.randn()\n",
    "    ar = 0.\n",
    "    qs = scipy.stats.norm(loc=0, scale=sigma_eps).rvs(size=mix_time)\n",
    "    us = scipy.stats.uniform.rvs(size=mix_time)\n",
    "    for n in range(1, mix_time):\n",
    "        theta_star = thetas[n-1] + qs[n]    \n",
    "        if us[n] < np.amin([1, r(theta_star, thetas[n-1])]):\n",
    "            thetas[n] = theta_star\n",
    "            ar += 1.\n",
    "        else:\n",
    "            thetas[n] = thetas[n-1]\n",
    "    return thetas, ar/mix_time\n",
    "\n",
    "def autocorr(thetas):\n",
    "    thetas_norm = (thetas-np.mean(thetas))/np.std(thetas)\n",
    "    rho = np.correlate(thetas_norm, \n",
    "                       thetas_norm, mode='full')\n",
    "    return rho[len(rho) // 2:]/len(thetas)\n",
    "\n",
    "def neff(rho):\n",
    "    T = np.where(rho < 0.)[0][0]\n",
    "    return len(rho)/(1 + 2*np.sum(rho[:T]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3), tight_layout=True)\n",
    "for sigma in [0.1, 1., 2., 10.]:\n",
    "    thetas, ar = metropolis(mix_time=2000, sigma_eps=sigma)\n",
    "    ax[0].plot(thetas)    \n",
    "    ax[1].plot(autocorr(thetas), label=str(sigma))\n",
    "    print(f\"Número efectivo de muestras para sigma {sigma}: {neff(autocorr(thetas)):0.4f}\")\n",
    "    print(f\"Fracción de aceptación: {ar:0.4f}\")\n",
    "\n",
    "ax[0].set_title('Traza')\n",
    "ax[1].set_title('Autocorrelación');\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la figura podemos ver que \n",
    "\n",
    "- Si el paso de las propuestas es muy corto, todos los pasos son aceptados, pero la correlación entre los mismos es alta por ser poco diversos\n",
    "- Si el paso de las propuestas es muy largo, se proponen demasiadas propuestas malas que terminan siendo rechazadas. La fracción de aceptación disminuye y la autocorrelación aumenta\n",
    "\n",
    "La fracción de aceptación es la cantidad de propuestas aceptadas dividido las propuestas totales. La sugerencia de los expertos es calibrar el algoritmo de Metropolis tal que alcance [una fracción de aceptación cercana a 23.4%](https://www.maths.lancs.ac.uk/~sherlocc/Publications/rwm.final.pdf) \n",
    "\n",
    "Una figura de mérito muy utilizada que se basa en la función de autocorrelación es el número de muestras efectivas\n",
    "\n",
    "$$\n",
    "n_{eff} = \\frac{N}{1 + 2 \\sum_{\\tau=1}^T \\rho(\\tau)}\n",
    "$$\n",
    "\n",
    "donde $N$ es la cantidad de muestras de la cadena y $T$ es el instante en que la autocorrelación se vuelve por primera vez negativa\n",
    "\n",
    "Idealmente quisieramos que $n_{eff} = N$, pero debido a que las muestras no son independientes en realidad tendremos $n_{eff} < N$\n",
    "\n",
    "Podemos calibrar nuestro algoritmo MCMC tal que maximicemos $n_{eff}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinning (adelgazamiento)\n",
    "\n",
    "Es una técnica para disminuir la autocorrelación de la traza. \n",
    "\n",
    "Consiste en submuestrear la traza, retendiendo sólo cada $t$ muestras, donde $t$ es el \"intervalo de adelgazamiento\". La idea es escoger este intervalo estudiando la función de autocorrelación\n",
    "\n",
    "Debido a la gran cantidad de muestras que se podrían descartar es preferible ajustar adecuadamente el paso de las propuestas por sobre esta técnica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadístico Gelman-Rubin\n",
    "\n",
    "Supongamos que no entrenamos una sino $M$ cadenas\n",
    "\n",
    "Otra forma de estudiar la convergencia en este caso es el estadístico Gelman Rubin o $\\hat r$\n",
    "\n",
    "Este estadístico compara la varianza (dispersión) dentro de la cadena con la varianza entre las $M$ cadenas. \n",
    "\n",
    "Si el valor de $\\hat r$ es cercano a uno es indicativo de que la cadena ha convergido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material extra\n",
    "\n",
    "- [Valores propios](https://www.cl.cam.ac.uk/teaching/1819/Probablty/materials/Lecture9_handout.pdf) y [cotas en los tiempos de mezcla](https://www.cl.cam.ac.uk/teaching/1920/Probablty/materials/Lecture10.pdf)\n",
    "- [Parallel tempering](https://www.pas.rochester.edu/~sybenzvi/courses/phy403/2016s/p403_18_mcmc.pdf)\n",
    "- [Artículo \"Una introducción conceptual a MCMC\"](https://arxiv.org/pdf/1909.12313.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INFO183",
   "language": "python",
   "name": "info183"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
