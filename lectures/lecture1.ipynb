{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, SelectionSlider, IntSlider\n",
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidad 2: Programación probabilística\n",
    "\n",
    "## Contenidos de la unidad\n",
    "\n",
    "- Introducción a los modelos generativos e inferencia bayesiana\n",
    "- Método de Integración por Monte Carlo. Proceso de Markov y caminata aleatoria\n",
    "- Algoritmos de muestreo por rechazo y Metropolis Hastings\n",
    "- Markov Chain Monte Carlo: Inferencia y Diagnósticos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué hemos aprendido hasta ahora?\n",
    "\n",
    "- Leyes fundamentales de probabilidades\n",
    "- Variables aleatorias, distribuciones y estadísticos\n",
    "- Ajuste de distribuciones y bondad de ajuste\n",
    "- Números pseudo aleatorios\n",
    "- Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es simular?\n",
    "\n",
    "- [\"Hacer que algo parezca real no siéndolo\"](https://www.rae.es/dpd/simular)\n",
    "- Del latín [simulâre: \"copiar, representar\"](https://es.wiktionary.org/wiki/simulaci%C3%B3n) o [simulatio \"acción y efecto de imitar algo\"](http://etimologias.dechile.net/?simulacio.n)\n",
    "- Reproducir artificialmente un fenómeno o las relaciones entrada-salida de un sistema\n",
    "\n",
    "\n",
    "> Una simulación digital es la aplicación de un modelo computacional para la predicción de eventos físicos o el comportamiento de sistemas de ingeniería"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/paradigms.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué simulamos en ingeniería y ciencia?\n",
    "\n",
    "La simulación nos permite explorar nuevas teorías o diseñar nuevos experimentos para probar dichas teorias\n",
    "\n",
    "Usando simulación podemos estudiar fenomenos que \n",
    "- no son observables\n",
    "- las observaciones o mediciones son demasiado caras, peligrosas o impracticas de realizar (poca información)\n",
    "\n",
    "Usando simulaciones podemos \n",
    "- analizar un sistema antes de haberlo construido\n",
    "- analizar situaciones a las que el sistema aun no ha sido expuesto\n",
    "- realizar predicciones sobre el comportamiento del sistema\n",
    "- analizar la influencia e interelaciones entre las variables del sistema y en consencuencia entender mejor su operación. [Ceteris paribus](https://en.wikipedia.org/wiki/Ceteris_paribus)\n",
    "\n",
    "\n",
    "Los simuladores son también ampliamente usados en educación\n",
    "\n",
    "Con el rápido avance y la disminución en costos de la computación, la simulación digital se ha vuelto una herramienta clave en muchas disciplinas (eléctrica, mecánica, química, aeroespacial, nuclear, biomédica, materiales, etc)\n",
    "\n",
    "> [Los principales desafíos de los simuladores están en la validación, verificación y medición de incerteza de los modelos](http://www.mcs-uab.com/docs/NSF.Simluation-Based_Engineering_Science.2006.pdf)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/morpho.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo generativo\n",
    "\n",
    "> [“What I cannot create, I do not understand.” Richard Feynman](https://jcs.biologists.org/content/joces/130/18/2941.full.pdf)\n",
    "\n",
    "Sea un observación descrita por $x$ que viene de una distribución de probabilidad $p^*(x)$\n",
    "\n",
    "Un modelo generativo es una aproximación $p_\\theta(x) \\approx p^*(x)$ con la cual podemos generar nuevos ejemplos  aleatorios de $x$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "with open(\"data/mistery_data.npy\", \"rb\") as f:\n",
    "    data = np.load(f) # Normal mu 10 y std 4\n",
    "\n",
    "print(data)\n",
    "\n",
    "dist = scipy.stats.norm # Seleccionar distribucion\n",
    "args = dist.fit(data)   # Ajustar parámetros con MLE\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = np.linspace(0, 20, num=20)\n",
    "stds = np.linspace(2, 10, num=20)\n",
    "logL = np.zeros(shape=(len(mus), len(stds)))\n",
    "for i, mu in enumerate(mus):\n",
    "    for j, std in enumerate(stds):\n",
    "        logL[i, j]= sum([dist.logpdf(x, loc=mu, scale=std) for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = dist(*args) # Crear modelo\n",
    "new_data = model.rvs(size=1000) # Generar datos\n",
    "print(new_data[:10])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), tight_layout=True)\n",
    "ax[0].pcolormesh(stds, mus, np.exp(logL), cmap=plt.cm.Reds)\n",
    "ax[1].hist(new_data, bins=20, density=True)\n",
    "x = np.linspace(model.ppf(0.001), model.ppf(0.999))\n",
    "ax[1].plot(x, model.pdf(x), 'k--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamentablemente los ejemplos de la vida real son demasiado complejos para modelarse con distribuciones sencillas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mnist_data.npy\", \"rb\") as f:\n",
    "    data = np.load(f) \n",
    "    \n",
    "dist = scipy.stats.multivariate_normal \n",
    "mu = np.mean(data.reshape(-1, 28*28), axis=0) # MLE de la media\n",
    "cov = np.cov(data.reshape(-1, 28*28), rowvar=False) # MLE de la covarianza\n",
    "model = dist(mean=mu, cov=cov+0.001*np.eye(28*28)) # Crear modelo\n",
    "new_data = model.rvs(size=10) # Generar datos\n",
    "\n",
    "fig, ax = plt.subplots(2, 10, tight_layout=True, figsize=(8, 2))\n",
    "for i in range(10):\n",
    "    ax[0, i].matshow(data[i], cmap=plt.cm.Greys_r)\n",
    "    ax[0, i].axis('off')\n",
    "    ax[1, i].matshow(new_data[i].reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    ax[1, i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es mucho más conveniente asumir que existe una variable latente $z$ con una distribución sencilla $p(z)$ que luego se modifica a través de una transformación no lineal (e.g. red neuronal) $p(x|z)$ para obtener un ejemplo de $x$\n",
    "\n",
    "En ese caso buscamos modelar la evidencia o verosimilitud marginal\n",
    "\n",
    "$$\n",
    "p(x) = \\int_{\\mathcal{z\\in Z}} p(x|z) p(z) \\,dz = \\int_{\\mathcal{z\\in Z}} p(x, z) \\,dz\n",
    "$$\n",
    "\n",
    "Esto además nos permite condicionar el sistema generador con variables que nos interesen\n",
    "\n",
    "[Los modelos generativos se investigan muy activamente hoy en día](https://openai.com/blog/generative-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('O1by05eX424')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordatorio: Teorema de Bayes\n",
    "\n",
    "De las propiedades de las probabilidades condicionales y la ley de probabilidades totales podemos escribir\n",
    "\n",
    "$$\n",
    "p(y|x) = \\frac{p(x|y) p(y)}{p(x)} = \\frac{p(x|y) p(y)}{\\int p(x|y) p(y) \\,dy}\n",
    "$$\n",
    "\n",
    "Tipicamente $x$ representa un conjunto de datos que hemos observado a través de un experimento e $y$ algún parámetro que queremos estimar. \n",
    "\n",
    "Discutamos: ¿Qué representan $p(y)$ y $p(y|x)$? ¿Cuándo es conveniente usar el teorema de bayes?\n",
    "\n",
    "\n",
    "\n",
    "### Desafio\n",
    "\n",
    "La marginalización de la variable latente, el cálculo de la esperanza de una variable continua o el cálculo de la evidencia en el teorema de Bayes requiere resolver integrales que pueden ser muy complicadas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de Monte Carlo\n",
    "\n",
    "Los métodos de Monte Carlo son una clase de métodos para resolver problemas matemáticos **usando muestras aleatorias** (o más bien pseudoaleatorias)\n",
    "\n",
    "Los métodos de Monte Carlo se usan para predecir el comportamiento de un sistema en un escenario incierto (aleatorio)\n",
    "\n",
    "Por ejemplo en la siguiente figura se predice el **valor esperado** del GDP per capita a un cierto horizonte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/montecarlo1.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero también pueden usarse en casos completamente determinísticos\n",
    "\n",
    "Por ejemplo en el caso de estimación de iluminación, la solución analítica es muchas veces infactible de calcular. En lugar de eso se puede aproximar usando una muestra aleatoria de rayos lanzados desde la fuente de iluminación\n",
    "\n",
    "Si lanzamos \"suficientes\" rayos al azar entonces podemos modelar bien la iluminación real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/montecarlo2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué relación tiene esto con una encuesta de opinión?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breve historia de los métodos de Monte Carlo\n",
    "\n",
    "En los 40s [Stanislaw Ulam](https://en.wikipedia.org/wiki/Stanislaw_Ulam), matemático polaco-américano, estaba en cama recuperandose de una enfermedad y pasaba el tiempo jugando solitario. Empezó a interesarse en calcular la probabilidad de ganar el juego de solitario. Trató de desarrollar las combinatorias sin éxito, era demasiado complicado\n",
    "\n",
    "Luego pensó\n",
    "\n",
    "> Supongamos que juego muchas manos, cuento las veces que gano y divido por la cantidad de manos jugadas\n",
    "\n",
    "Sin embargo el había jugado muchas manos sin ganar, posiblemente le tomaría años hacer este conteo\n",
    "\n",
    "Ulam pensó entonces en simular el juego usando un computador, por lo que recurrió a [John von Neumann](https://en.wikipedia.org/wiki/John_von_Neumann), quien implementó el algoritmo propuesto por Ulam en el [ENIAC](https://en.wikipedia.org/wiki/ENIAC)\n",
    "\n",
    "Más adelante este algoritmo fue central en las simulaciones realizadas en el proyecto Manhattan. En aquel entonces [Nicholas Metropolis](https://en.wikipedia.org/wiki/Nicholas_Metropolis), colega de von Neumann y Ulam sugirió el nombre de Monte Carlo, haciendo alusión al famoso [casino de Monte Carlo](https://es.wikipedia.org/wiki/Casino_de_Montecarlo) que se encuentra en principado de Monaco en Europa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esquema general  de un método de Monte Carlo\n",
    "\n",
    "1. Se muestrean aleatoriamente las variables de entrada $X$\n",
    "1. Se calcula una \"cantidad de interés\" $Y=g(x)$ (variable de salida)\n",
    "1. Se reduce el resultando usando estadísticos, por ejemplo $\\bar Y$ y $\\sigma_Y$\n",
    "\n",
    "La cantidad de interés es también una variable aleatoria. Es conveniente que las variables de entrada sigan una distribución sencilla (e.g. uniforme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimando el valor esperado de una función\n",
    "\n",
    "El valor esperado de una función $g(x)$ es\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[g] = \\int g(x) f(x) \\,dx\n",
    "$$\n",
    "\n",
    "donde $f(x)$ es la densidad de $x$\n",
    "\n",
    "Si la función y/o la integral son muy complicadas de calcular podemos en lugar de eso\n",
    "\n",
    "- Muestrar aleatoriamente $N$ valores $x_i \\sim f(x)$\n",
    "- Evaluar $y_i = g(x_i)$\n",
    "- aproximar el valor esperado como $V\\frac{\\sum_i y_i}{N}$\n",
    "\n",
    "donde $V = \\int f(x) \\,dx$ es el volumen de integración\n",
    "\n",
    "Cuando el método de Monte Carlo se usa para calcular un valor esperado se llama \"Integración por Monte Carlo\"\n",
    "\n",
    "## Ejemplo: Calculando $\\pi$ usando integración por Monte Carlo\n",
    "\n",
    "El área es la integral definida de la función en su dominio\n",
    "\n",
    "- La fórmula análitica del área de un cuadrado de lado $a$ es $a^2$\n",
    "- La fórmula analítica del área de un circulo de radio $a$ es $\\pi a^2$\n",
    "\n",
    "Podemos estimar $\\pi$ como el cociente $\\frac{A_{circulo}}{A_{cuadrado}}$. Estimemos las áreas usando integración por Monte Carlo\n",
    "\n",
    "- ¿Cómo cambia el resultado con $N$?\n",
    "- ¿Qué ocurre si hay un sesgo al generar las muestras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x1, x2):\n",
    "    return (x1-0)**2 + (x2-0)**2 -1. <= 0.\n",
    "\n",
    "N = 1000\n",
    "\n",
    "x = np.random.rand(N, 2) # El volumen de integración es 1\n",
    "N_inside = sum(g(x[:, 0], x[:, 1]))\n",
    "print(4*N_inside/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2 = np.meshgrid(np.linspace(0, 1, num=1000), \n",
    "                     np.linspace(0, 1, num=1000))\n",
    "fig, ax = plt.subplots(figsize=(4, 3), tight_layout=True)\n",
    "ax.contourf(X1, X2, g(X1, X2), cmap=plt.cm.RdBu_r); \n",
    "ax.set_aspect('equal')\n",
    "ax.scatter(x[:, 0], x[:, 1], s=1, c='k', alpha=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logN = np.arange(0, 7, step=0.1)\n",
    "pi = np.zeros_like(logN)\n",
    "errpi = np.zeros_like(pi)\n",
    "\n",
    "for i, logn in enumerate(logN):\n",
    "    xr = np.random.rand(int(10**logn), 2)\n",
    "    pi[i] = 4.*np.mean(g(xr[:, 0], xr[:, 1]))    \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 2), tight_layout=True)\n",
    "ax.plot(logN, pi)\n",
    "ax.axhline(np.pi, linestyle='--', color='r', alpha=.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento de lanzar una moneda\n",
    "\n",
    "¿Cuál es la probabilidad de que el próximo lanzamiento sea cara?\n",
    "\n",
    "- Si lancé la moneda una vez y salió cara\n",
    "- Si lancé la moneda dos veces y en ambas salió cara\n",
    "- Si lancé la moneda 100 veces y en todas salió cara\n",
    "- Si lancé la moneda 100 veces y en 52 salió cara y 48 sello\n",
    "\n",
    "¿Cómo es la varianza en cada caso? ¿Qué relación tiene que ver nuestra confianza sobre el resultado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas para el futuro:\n",
    "- Usar sólo un tipo de dígito, mostrar con más digitos y cambiar a una distribución acotada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
